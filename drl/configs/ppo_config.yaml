# PPO Training Configuration for Traffic Intersection DRL - ULTRA-OPTIMIZED MODE with FIXED TIMING

# Training Parameters - OPTIMIZED FOR 4 CRITICAL PARAMETERS
total_timesteps: 10000  # Increased due to faster convergence with 4 critical params
eval_freq: 1000         # Less frequent evaluation for speed
checkpoint_freq: 1000   # Less frequent checkpoints

# PPO Algorithm Parameters - OPTIMIZED FOR 4 CRITICAL PARAMETERS
learning_rate: 5e-4     # Higher LR for critical params
n_steps: 150            # Increased for better exploration with 4 critical params
batch_size: 64          # Larger batch for stable training
n_epochs: 8             # More epochs for critical parameter learning
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01          # Small entropy bonus for exploration
vf_coef: 0.5
max_grad_norm: 0.5

# FIXED TIMING CONFIGURATION - Synchronized intervals for proper vehicle control
timing_config:
  # FIXED: New synchronized time hierarchy
  fixed_delta_seconds: 0.1          # Simulation step: 0.1s (10 FPS)
  logic_update_interval: 1.0        # Decision step: 1.0s (10 sim steps per decision)
  auction_interval: 4.0             # Auction cycle: 4.0s (4 decisions per cycle)
  bidding_duration: 2.0             # Bidding phase: 2.0s (50% of cycle)
  deadlock_check_interval: 8.0      # System check: 8.0s (2 auction cycles)
  
  # This ensures PERFECT synchronization:
  # - 10 sim steps per decision
  # - 4 decisions per auction cycle  
  # - Vehicles properly respect 'wait' commands
  # - No more "all vehicles moving together" issue

# Simulation Configuration - FASTER EPISODES with FIXED TIMING
sim_config:
  map: 'Town05'
  max_steps: 128      # Reduced from 2000
  spawn_rate: 1.0
  intersection_center: [-188.9, -89.7, 0.0]
  
  # FIXED: Apply new timing configuration
  fixed_delta_seconds: 0.1
  logic_update_interval_seconds: 1.0
  auction_interval: 4.0
  bidding_duration: 2.0

# Reward Configuration - FIXED VALUES (not trainable)
reward_config:
  vehicle_exit_reward: 10.0      # FIXED: Not trainable
  throughput_bonus: 0.01         # FIXED: Not trainable
  acceleration_penalty_threshold: 3.0
  acceleration_penalty_factor: 2.0
  efficiency_bonus: 5.0
  collision_penalty: 100.0       # FIXED: Not trainable
  deadlock_penalty: 800.0        # FIXED: Not trainable
  step_penalty: 0.1

# ULTRA-OPTIMIZED: Only 4 trainable parameters instead of 8 parameters (50% reduction)
# These are the MOST IMPORTANT parameters for deadlock avoidance
nash_hyperparams:
  path_intersection_threshold:
    range: [2.5, 2.5]  # FIXED: Not trainable
    default: 2.5
    description: "Distance threshold for detecting path intersections (FIXED)"
  platoon_conflict_distance:
    range: [15.0, 15.0]  # FIXED: Not trainable
    default: 15.0
    description: "Distance at which platoons are considered in conflict (FIXED)"

# Training Schedule
schedule:
  warmup_steps: 50000
  decay_steps: 100000
  min_learning_rate: 1e-5

# Evaluation
evaluation:
  n_eval_episodes: 5
  eval_deterministic: true
  eval_render: false

# Logging
logging:
  tensorboard: false
  csv: true
  metrics_freq: 100
  save_freq: 1000

# FIXED TIMING NOTES:
# - New synchronized time hierarchy prevents vehicles from moving together
# - 1.0s decision intervals provide better control responsiveness
# - 4.0s auction cycles align perfectly with decision steps
# - 8.0s deadlock checks maintain system health monitoring
# - Vehicles now properly respect 'wait' commands due to synchronized timing
